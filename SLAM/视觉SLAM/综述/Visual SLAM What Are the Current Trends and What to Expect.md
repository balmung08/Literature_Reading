### 视觉SLAM综述
> **Visual SLAM: What Are the Current Trends and What to Expect?**
> Ali Tourani, Hriday Bavle, Jose Luis Sanchez-Lopez and Holger Voos

### 直接法与间接法
间接法从物体纹理中提取特征点，并在连续帧中匹配描述子来进行跟踪，这样对于每帧的光强变化具有较强的鲁棒性
直接法依据像素级原始数据估计相机运动，利用所有相机输出像素并按照其受约束的方面在连续帧中进行跟踪；可以得到更多的信息并能实现更高精度的3D重建，在纹理少的环境中效果更好且不需要考虑特征提取的效率，但是通常面临大规模优化问题

### 成熟的VSLAM方法
**MonoSLAM$\Rightarrow$PTAM$\Rightarrow$DTAM$\Rightarrow$SLAM++$\Rightarrow$LSD-SLAM$\Rightarrow$SVO$\Rightarrow$ORB-SLAM$\Rightarrow$DSO$\Rightarrow$CNN-SLAM$\Rightarrow$ORB-SLAM2.0$\Rightarrow$ORB-SLAM3.0**
* 首次实时单目VSLAM的尝试是Mono-SLAM(间接法)，可以使用扩展卡尔曼滤波估计现实物体，此时没有全局优化与回环检测，且地图仅包括地标而没有其他信息
* PTAM(间接法)即并行tracking和mapping，将VSLAM系统分为了这两个主要线程用于降低计算成本，当tracking实时估计相机运动时mapping预测特征点的位置；使用了FAST角点检测器进行关键点的匹配与跟踪；算法性能优于Mono-SLAM，但设计复杂且第一步需要手动设置
* DTAM(直接法)即测量深度值与运动参数来构建地图，通过将整个帧与深度图对齐来确定相机姿态，虽然可以提供地图的详细表示但是计算成本很高
* SLAM++(间接法)首次尝试在SLAM中利用语义信息，采样RGBD传感器输出并执行3D相机姿态估计和跟踪以实现位姿图，合并从场景中的语义对象获得的相对3D姿态来优化预测位姿
* SVO为半直接视觉里程计，结合了间接法与直接法来进行运动估计与建图，可以与其他相机一起工作，并使用姿态细化模块来最小化重投影误差
* LSD-SLAM使用姿态图估计模块重建大规模地图，拥有了全局优化与回环检测模块；但是其初始化阶段需要平面中的所有点，需要大量计算
* CNN-SLAM(间接法)是基于CNN来处理相机位姿估计的输入帧并利用关键帧进行深度估计的方法，其思想之一就是将帧分割成较小的部分来更好的理解环境
* DSO(直接法)将直接法与稀疏重建结合提取图像块中的最高强度点；通过跟踪稀疏像素集，考虑图像形成参数并使用间接跟踪方法。DSO只能在使用光度标定相机时获取完美精度，普通相机效果一般
* ORB-SLAM系列(间接法)，其1.0版本能够使用关键帧计算相机位置与环境结构；2.0具有tracking、mapping和回环检测三个线程，但是重建的地图比例未知，无法直接使用于导航，同时无法在没有纹理的区域或具有重复图案的区域中工作；3.0适用于各种相机类型并且提供了改进的姿态估计输出

### VSLAM的各个模块
* **传感器与数据采集**
* * 传统使用的相机包括单目、多目、深度相机，可以获取丰富的环境信息，但是在亮度过高或过低情况下效果较差；另外，由于成像延迟，对高速运动的环境效果也不好
* * 事件相机并不产生亮度强度帧，而是当像素的亮度变化超过阈值时返回信号，因此只对运动的目标产生反应且由于返回的信息简单，延迟很低，适用于恶劣光照与高速环境下，而在常规环境下效果则不如常规相机；另外，由于事件相机主要提供环境的变化信息，传统的视觉算法很难处理这种信息，需要算法的创新
* * 相机无论怎么设计都很难同时解决运动模糊、极端光照下特征不匹配、高速变化时动态对象遗漏等现象，因此与其他传感器融合也是可以采取的解决方案
* **应用场景**
* * 环境中的移动对象会导致系统复杂化，降低状态估计质量；通常使用光流法、随机采样一致性等方法检测场景中的移动并将移动分类为异常值，在mapping时忽略他们；在动态环境中的系统通常使用几何与语义信息结合改进定位方案
* * 环境通常分为室内与室外，VSLAM可能在两种环境中表现出截然不同的性能
* **视觉特征处理**
* * 利用视觉特征并利用特征描述子信息进行状态估计是间接法的核心步骤之一，传统特征提取算法有SIFT,SURF,FAST,BRIEF,ORB等；与SIFT、SURF相比，ORB具有快速且不损失很大准确度的优点。传统算法很难适应复杂情况，现在通常使用CNN提取不同阶段图像的深层特征，包括视觉里程计、姿态估计和回环检测。
* **语义层**
* * 语义信息添加到纯几何信息后可以提供环境更多信息，效果更好；最新的方法使用CNN进行语义SLAM，除了tracking、mapping和回环检测以外增加了一个NRCC步骤，NRCC可以过滤视频帧中的时态物体，包含一个屏蔽分割过程，分离帧中如人类一样的不稳定实例，减少待处理的特征点数量，简化计算部分并增加了鲁棒性；不过使用语义分割通常会增加计算成本，这也是目前的挑战性问题
    > 个人理解就是先用语义分割把运动物体或者不需要处理的物体识别出来扣掉，再进行特征提取时就全是静态地图，可以减少运动物体对姿态估计的负面影响

### 基于目标的VSLAM分类
* **目标一：多传感器处理**
* * 一台相机重建轨迹比较困难，可以使用多相机协调
* * 使用相机以外的多传感器进行融合
* **目标二：姿态估计（确定特征）**
* * 使用线/点数据作为特征
* * 使用其他指标作为特征
* * 使用深度学习提取特征
* **目标三：真实环境可行性**
* * 动态环境、大规模环境下使用
* **目标四：资源限制**
* * 计算能力有限的设备上：轻量级流程设计
* * 计算迁移：只在终端上运行部分模块，其余部分迁移到边缘计算设备；由于模块需要解耦会导致架构复杂性增大，另外长期场景中性能容易下滑
* **目标五：多功能性**
* 针对方法的适应性、扩展性进行开发；比如可以兼容多种摄像头的数据（适应性）或框架可以与其他SLAM方法一起使用以获得更好性能（扩展性）
* **目标六：视觉里程计**
* * 利用深度神经网络(CNN、RCNN、RNN、NGO神经图优化等)、深度帧间处理、各种特征处理等方法尽可能高精度的确认机器人的位姿

### 研究趋势
* **已有研究数据统计**
* * 大多数VSLAM方法都是独立的，ORB-SLAM系是用于构建新框架的基础平台
* * 目前最多人试图解决的问题是视觉里程计问题，其次是真实世界可行性与姿态估计
* * 大多数VSLAM方法目前都没有使用语义信息，可能原因有：
    在许多情况下，训练识别对象的模型并将其用于语义分割的计算成本相当大，这可能会增加处理时间
    大多数基于几何的VSLAM方案都被设计为即插即用设备，因此它们可以尽可能少地使用相机数据进行定位和建图
    从场景中提取的错误信息也会给过程中增加更多的噪声
* * 过半的方法都可以在动态环境下工作，但是也有只能在静态环境下工作的方法
* * 过半的论文仅测试了室内性能，四成论文测试了室内室外性能，极少部分仅测试了室外环境性能
* **趋势分析**
* * 引入深度学习
* * 信息获取量与计算成本的平衡
* * 语义分割（语义信息可用于姿态估计、轨迹规划与回环检测）
* * 回环检测
* * 特殊场景的应用